{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78743758",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lk/c6gkc6x5345_rvndycqph7nm0000gn/T/ipykernel_10598/3712951357.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "totimestamp = lambda s: np.int32(time.mktime(datetime.strptime(s, \"%d/%m/%Y\").timetuple()))\n",
    "train_window = [totimestamp(\"01/01/2019\"), totimestamp(\"30/05/2021\")]\n",
    "test_window = [totimestamp(\"01/06/2021\"), totimestamp(\"30/06/2021\")]\n",
    "BATCH_SIZE    = 10\n",
    "SEQ_LENGTH    = 2160\n",
    "EPOCHS        = 40\n",
    "DROPOUT       = 0.1\n",
    "NUM_LAYERS    = 10\n",
    "INPUT_DIM     = 238\n",
    "OUTPUT_SIZE   = 1\n",
    "HIDDEN_SIZE   = 60\n",
    "LEARNING_RATE = 0.001\n",
    "STATE_DIM     = NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1250f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./g-research-crypto-forecasting/train.csv')\n",
    "df.dropna(axis = 0, inplace = True)\n",
    "\n",
    "def log_return(series, periods=1):\n",
    "    return np.log(series).diff(periods=periods)\n",
    "\n",
    "data = df.set_index(\"timestamp\")\n",
    "upper_shadow = lambda asset: asset.High - np.maximum(asset.Close,asset.Open)\n",
    "lower_shadow = lambda asset: np.minimum(asset.Close,asset.Open)- asset.Low\n",
    "gap          = lambda asset: asset.High - asset.Low\n",
    "trend        = lambda asset: asset.Close - asset.Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5f212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiqinshen/mambaforge/lib/python3.9/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "inform_list = []\n",
    "for i in range(14):\n",
    "    inform_list.extend([\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=1), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=2), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=3), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=4), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=5), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=6), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=7), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=8), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=9), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=10), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=50), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=100), \\\n",
    "        log_return(data[data[\"Asset_ID\"]==i].VWAP,periods=500), \\\n",
    "        upper_shadow(data[data[\"Asset_ID\"]==i]), \\\n",
    "        lower_shadow(data[data[\"Asset_ID\"]==i]), \\\n",
    "        gap(data[data[\"Asset_ID\"]==i]), \\\n",
    "        trend(data[data[\"Asset_ID\"]==i])\n",
    "    ])\n",
    "X = pd.concat(inform_list, axis = 1)\n",
    "y = data[data[\"Asset_ID\"]==0].Target\n",
    "X = X.loc[y.index].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "X_train = X.loc[train_window[0]:train_window[1]].fillna(0).to_numpy()  # filling NaN's with zeros\n",
    "y_train = y.loc[train_window[0]:train_window[1]].fillna(0).to_numpy()\n",
    "X_test = X.loc[test_window[0]:test_window[1]].fillna(0).to_numpy() \n",
    "y_test = y.loc[test_window[0]:test_window[1]].fillna(0).to_numpy() \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "dl = DataLoader(X_train_scaled, batch_size = 64, shuffle = True, drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2169de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    \"\"\"\n",
    "    #dim ==> 8 ==> #dim\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(238, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 238),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f221a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                          | 1/100 [00:26<43:47, 26.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 0.8977740478416228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▌                                     | 11/100 [04:47<38:09, 25.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loss: 0.8145235352109436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▊                                 | 21/100 [09:06<34:25, 26.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 loss: 0.8066206114010864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████                             | 31/100 [13:25<29:53, 26.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 loss: 0.8032873481189333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████▏                        | 41/100 [17:47<26:11, 26.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 loss: 0.8018188981833761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████▍                    | 51/100 [22:13<21:42, 26.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 loss: 0.8008817999879263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████▌                | 61/100 [26:39<17:21, 26.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 loss: 0.8001096879772592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████▊            | 71/100 [31:01<12:33, 25.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 loss: 0.7996038359066329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████        | 81/100 [35:23<08:18, 26.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 loss: 0.7994603278748269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████▏   | 91/100 [39:52<04:03, 27.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 loss: 0.7992111459549432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [43:48<00:00, 26.29s/it]\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "model = AE().to(device)\n",
    "criteon = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    running_training_loss = 0.0\n",
    "    for idx, (x_batch) in enumerate(dl):\n",
    "        x_batch = x_batch.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        _, output = model(x_batch)\n",
    "        loss = criteon(output, x_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        running_training_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        training_loss = running_training_loss/idx\n",
    "        print(epoch, 'loss:', training_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
